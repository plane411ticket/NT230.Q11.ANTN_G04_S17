{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c90cf8ae-3966-4461-93fa-9c5773368304",
   "metadata": {},
   "source": [
    "# Import library and support function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d8bdf20-6037-4e55-944a-299a6f16dc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-iec2023se05/pytorch_gpu_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm import tqdm \n",
    "from torch.utils.data import Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "import json\n",
    "import os\n",
    "from datasets import load_dataset\n",
    "import torch_geometric.data \n",
    "import data\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.metrics import (ConfusionMatrixDisplay, roc_auc_score, precision_score, average_precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error, roc_curve, auc, classification_report,auc,confusion_matrix,matthews_corrcoef)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.nn import GATConv\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import global_add_pool\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b1a3316-5319-4e92-9b54-14ff9b296a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"X_matrix_final.json\",'r') as f:\n",
    "    SEMANTIC_EMBEDDING = json.load(f)\n",
    "\n",
    "# Model hyperparameters\n",
    "EPOCH_LIST = [25, 50, 75, 100, 125, 150, 175, 200, 225, 250, 275, 300, 400, 500]          \n",
    "BATCH_LIST = [32, 64, 128, 192, 256, 512] \n",
    "EMBEDDED_DIMENSION = 768\n",
    "HIDDEN_DIM = 12\n",
    "NUM_HEADS = 12\n",
    "OUTPUT_DIM = 1\n",
    "# TRAIN_EPOCHS = 100\n",
    "LEARNING_RATE = 1e-4\n",
    "# BATCH_SIZE = 128\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Result\n",
    "RESULT_PATH = \"Result/v03_Final_Train_BERT_BRUTEFORCE_EPOCH_BATCH02.csv\"\n",
    "CHART_PATH = \"Result/Charts03\"\n",
    "res_df = pd.DataFrame(columns=[\n",
    "    \"Data Type\",\n",
    "    \"STT\",\n",
    "    \"Train Epochs\",\n",
    "    \"Batch Size\",\n",
    "    \"Result Type\",\n",
    "    \"Loss\",\n",
    "    \"Accuracy\",\n",
    "    \"Precision\",\n",
    "    \"Recall\",\n",
    "    \"F1-Score\",\n",
    "    \"TNR\",\n",
    "    \"Confusion Matrix\",\n",
    "    \"Training Time\",\n",
    "    \"Testing Time\"\n",
    "])\n",
    "res_df.to_csv(RESULT_PATH, mode='a', header=not os.path.exists(RESULT_PATH), index=False)\n",
    "\n",
    "# Loss\n",
    "# EPOCHS_LOSS = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab4a00ed-1daa-4fd8-ad92-7bdd70480e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION - API SEQUENCE TO GRAPH\n",
    "def API_seq_to_graph(api_sequence, label):\n",
    "    api_sequence = [api for api in api_sequence if isinstance(api, str) and api]\n",
    "    if len(api_sequence) < 2:\n",
    "        return None\n",
    "\n",
    "    # Graph edges\n",
    "    transitions = [(api_sequence[i], api_sequence[i+1]) for i in range(len(api_sequence)-1)]\n",
    "    edge_counters = Counter(transitions)\n",
    "\n",
    "    unique_apis = list(set(api_sequence))\n",
    "    apis_call_time = {api: idx for idx, api in enumerate(unique_apis)}\n",
    "    number_nodes = len(unique_apis)\n",
    "\n",
    "    src, dst, edge_weights = [], [], []\n",
    "    for (u, v), count in edge_counters.items():\n",
    "        src.append(apis_call_time[u])\n",
    "        dst.append(apis_call_time[v])\n",
    "        edge_weights.append(count)\n",
    "\n",
    "    edge_index = torch.tensor([src, dst], dtype=torch.long)\n",
    "    edge_attr = torch.tensor(edge_weights, dtype=torch.float).view(-1,1)\n",
    "\n",
    "    # Node features\n",
    "    nodes_features = []\n",
    "    for api in unique_apis:\n",
    "        embedding = SEMANTIC_EMBEDDING.get(api)\n",
    "        if embedding is None:\n",
    "            nodes_features.append(np.zeros(EMBEDDED_DIMENSION))\n",
    "        else:\n",
    "            nodes_features.append(embedding)\n",
    "    nodes_features = np.array(nodes_features)\n",
    "    X = torch.tensor(nodes_features, dtype=torch.float32)\n",
    "    y = torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "    return Data(x=X, edge_index=edge_index, edge_attr=edge_attr, y=y, num_nodes=number_nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65fb166e-3320-476c-b5d2-aeac5fc178f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DawnGNN_GAT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DawnGNN_GAT, self).__init__()\n",
    "        self.conv1 = GATConv(EMBEDDED_DIMENSION, HIDDEN_DIM, heads=NUM_HEADS, dropout=0.6)\n",
    "        self.conv2 = GATConv(HIDDEN_DIM * NUM_HEADS, HIDDEN_DIM, heads=1, concat=False, dropout=0.6)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(HIDDEN_DIM, HIDDEN_DIM//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(HIDDEN_DIM//2, OUTPUT_DIM)\n",
    "        )\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        x = F.elu(self.conv1(x, edge_index))\n",
    "        x = F.elu(self.conv2(x, edge_index))\n",
    "        x = global_add_pool(x, batch)\n",
    "        x = self.classifier(x)\n",
    "        return torch.sigmoid(x).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2289be21-eba4-4bf8-a4c6-fb25e68402e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATION FUNCTION\n",
    "def evaluate_model(DATASET, epoch, model, loader, BATCH_SIZE, EPOCHS_LOSS, TRAIN_EPOCHS, device, criterion, val_test, training_time, cumulative_testing_time=0):\n",
    "    model.eval()\n",
    "    start_test = time.time()\n",
    "    total_loss = 0\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            out = model(data)\n",
    "            loss = criterion(out.float(), data.y.float())\n",
    "            total_loss += loss.item() * data.num_graphs\n",
    "            y_pred.extend((out>0.5).long().cpu().tolist())\n",
    "            y_true.extend(data.y.long().cpu().tolist())\n",
    "\n",
    "    end_test = time.time()\n",
    "    testing_time = end_test - start_test\n",
    "    cumulative_testing_time += testing_time\n",
    "    precision = precision_score(y_true, y_pred, average='binary', zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average='binary', zero_division=0)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='binary', zero_division=0)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    TNR = tn / (tn + fp)\n",
    "    FPR = fp / (fp + tn)\n",
    "    FNR = fn / (fn + tp)\n",
    "    NPV = tn / (tn + fn)\n",
    "\n",
    "    if (val_test == 'Test'):\n",
    "        LABELS = ['Benign', 'Malware']\n",
    "        plt.figure(figsize=(6,5))\n",
    "        sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', xticklabels=LABELS, yticklabels=LABELS)\n",
    "        plt.title('Confusion Matrix', fontsize=17, pad=20)\n",
    "        plt.ylabel('Actual', fontsize=13)\n",
    "        plt.xlabel('Prediction', fontsize=13)\n",
    "        plt.gca().xaxis.set_label_position('top') \n",
    "        plt.gca().xaxis.tick_top()\n",
    "        plt.show()\n",
    "\n",
    "    res_df.loc[len(res_df)] = [\n",
    "        DATASET,\n",
    "        epoch,\n",
    "        TRAIN_EPOCHS,\n",
    "        BATCH_SIZE,\n",
    "        val_test,\n",
    "        total_loss/len(loader.dataset),\n",
    "        acc,\n",
    "        precision,\n",
    "        recall,\n",
    "        f1,\n",
    "        TNR,\n",
    "        str(cm.tolist()),\n",
    "        training_time,\n",
    "        cumulative_testing_time\n",
    "    ]\n",
    "    if ((epoch == TRAIN_EPOCHS) and (val_test == 'Test')):\n",
    "        res_df.to_csv(RESULT_PATH, mode='a', header=False, index=False)\n",
    "\n",
    "    avg_epoch_loss = total_loss/len(loader.dataset)\n",
    "    EPOCHS_LOSS.append(avg_epoch_loss)\n",
    "\n",
    "    return total_loss/len(loader.dataset), acc, f1, precision, recall, TNR, cumulative_testing_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7af6fd1e-7108-4653-9b7b-5ca7437b9a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_train_test_gat():\n",
    "    print(\"==================== CONVERT API SEQUENCE TO GRAPH ====================\")\n",
    "    # LOAD DATASET\n",
    "    dataset = [\"APIMDS\", \"MalBehavD-V1-dataset\", \"WINDOWS_PE_APICALLS\"]\n",
    "    # Load Dataset\n",
    "    for ds in dataset: \n",
    "        DATASET_PATH = f\"Dataset/{ds}.csv\"\n",
    "        DATASET = ds    \n",
    "        # DATASET_PATH = \"Dataset/WINDOWS_PE_APICALLS_CSV9.csv\"\n",
    "        # DATASET = \"WINDOWS_PE_APICALLS_CSV9\"\n",
    "        df = pd.read_csv(DATASET_PATH, low_memory=False)\n",
    "        if ds == 'MalBehavD-V1-dataset':\n",
    "            start_api = 2\n",
    "            label_col_name = 'labels'\n",
    "        elif ds == 'APIMDS':\n",
    "            start_api = 2\n",
    "            label_col_name = 'labels'\n",
    "        elif ds == 'WINDOWS_PE_APICALLS':\n",
    "            start_api = 1\n",
    "            df['labels'] = df['Malware'].apply(lambda x: 0 if x.lower() in ['benign', 'normal'] else 1)\n",
    "            label_col_name = 'labels'\n",
    "            \n",
    "        # print(df.head(5))\n",
    "        data_list = []\n",
    "        for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "            api_sequence = row.iloc[2:].dropna().tolist()\n",
    "            label = float(row['labels'])\n",
    "            graph = API_seq_to_graph(api_sequence, label)\n",
    "            if graph is not None:\n",
    "                data_list.append(graph)\n",
    "    \n",
    "        # Split dataset\n",
    "        train_data, temp_data = train_test_split(data_list, test_size=0.2, random_state=42)\n",
    "        val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n",
    "    \n",
    "        # Model & optimizer\n",
    "        model = DawnGNN_GAT().to(DEVICE)\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    \n",
    "        # Training\n",
    "        for epoch in EPOCH_LIST:\n",
    "            for batch in BATCH_LIST:    \n",
    "                TRAIN_EPOCHS = epoch\n",
    "                BATCH_SIZE = batch\n",
    "                EPOCHS_LOSS = []\n",
    "    \n",
    "                train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "                val_loader = DataLoader(val_data, batch_size=BATCH_SIZE)\n",
    "                test_loader = DataLoader(test_data, batch_size=BATCH_SIZE)\n",
    "                \n",
    "                print(f\"\\n===== RUNNING WITH EPOCH={epoch}  |  BATCH={batch} =====\")\n",
    "                cumulative_testing_time = 0\n",
    "                for epoch in range(1, TRAIN_EPOCHS+1):\n",
    "                    model.train()\n",
    "                    start_train = time.time()\n",
    "                    total_loss = 0\n",
    "                    for data in train_loader:\n",
    "                        optimizer.zero_grad()\n",
    "                        data = data.to(DEVICE)\n",
    "                        out = model(data)\n",
    "                        loss = criterion(out.float(), data.y.float())\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        total_loss += loss.item() * data.num_graphs\n",
    "            \n",
    "                    end_train = time.time()\n",
    "                    training_time = end_train - start_train\n",
    "                    \n",
    "                    val_loss, val_acc, val_f1, val_pre, val_recall, val_TNR, cumulative_testing_time = evaluate_model(DATASET, epoch, model, val_loader, BATCH_SIZE, EPOCHS_LOSS, TRAIN_EPOCHS, DEVICE, criterion, val_test=\"Validation\", training_time=training_time,\n",
    "                        cumulative_testing_time=cumulative_testing_time)\n",
    "                    print(f\"Epoch {epoch} | Train Loss: {total_loss/len(train_data):.4f} | Val Acc: {val_acc:.4f} | Val F1: {val_f1:.4f} | Val Precision: {val_pre:.4f} | Val Recall: {val_recall:.4f} | Val TNR: {val_TNR:.4f}\")\n",
    "    \n",
    "                # # if __name__ == \"__main__\":\n",
    "                # print(\"==================== TRAINING ====================\")\n",
    "                # model, test_loader, criterion = main_train_gat()\n",
    "    \n",
    "                plt.figure(figsize=(8,5))\n",
    "                plt.plot(range(1, len(EPOCHS_LOSS)+1), EPOCHS_LOSS, marker='o', linestyle='-')\n",
    "                plt.title(\"Training Loss per Epoch\", fontsize=15)\n",
    "                plt.xlabel(\"Epoch\", fontsize=13)\n",
    "                plt.ylabel(\"Loss\", fontsize=13)\n",
    "                plt.grid(True)\n",
    "                \n",
    "                chart_path = f\"{CHART_PATH}/{DATASET}_Loss_E{epoch}_B{batch}.png\"\n",
    "                plt.savefig(chart_path, dpi=300)    \n",
    "                plt.show()\n",
    "    \n",
    "                print(\"==================== TESTING ====================\")\n",
    "                test_loss, test_acc, test_f1, test_precision, test_recall, test_TNR, cumulative_testing_time = evaluate_model(DATASET, epoch, model, test_loader, BATCH_SIZE, EPOCHS_LOSS, TRAIN_EPOCHS, DEVICE, criterion, val_test=\"Test\", training_time=0, cumulative_testing_time=0)\n",
    "                print(\"\\n=======================================================\")\n",
    "                print(f\"✅ FINAL TEST PERFORMANCE (GAT Classifier):\")\n",
    "                print(f\"Accuracy: {test_acc:.4f} | F1-Score: {test_f1:.4f} | Loss: {test_loss:.4f} | Recall: {test_recall:.4f} | Precision: {test_precision:.4f} | TNR: {test_TNR:.4f}\")\n",
    "                print(\"=======================================================\")\n",
    "\n",
    "            \n",
    "    return model, test_loader, criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3da86e1-d7ac-4360-b138-a9c3e9d90d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== TRAINING ====================\n",
      "==================== CONVERT API SEQUENCE TO GRAPH ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 1021/17569 [00:08<02:20, 117.44it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# if __name__ == \"__main__\":\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m==================== TRAINING ====================\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m model, test_loader, criterion = \u001b[43mmain_train_test_gat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mmain_train_test_gat\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     26\u001b[39m api_sequence = row.iloc[\u001b[32m2\u001b[39m:].dropna().tolist()\n\u001b[32m     27\u001b[39m label = \u001b[38;5;28mfloat\u001b[39m(row[\u001b[33m'\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m graph = \u001b[43mAPI_seq_to_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     30\u001b[39m     data_list.append(graph)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 32\u001b[39m, in \u001b[36mAPI_seq_to_graph\u001b[39m\u001b[34m(api_sequence, label)\u001b[39m\n\u001b[32m     30\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     31\u001b[39m         nodes_features.append(embedding)\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m nodes_features = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m X = torch.tensor(nodes_features, dtype=torch.float32)\n\u001b[32m     34\u001b[39m y = torch.tensor(label, dtype=torch.float32)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "print(\"==================== TRAINING ====================\")\n",
    "model, test_loader, criterion = main_train_test_gat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ca906b-d408-404f-bcab-1446e3bf4dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# plt.figure(figsize=(8,5))\n",
    "# plt.plot(range(1, len(EPOCHS_LOSS)+1), EPOCHS_LOSS, marker='o', linestyle='-')\n",
    "# plt.title(\"Training Loss per Epoch\", fontsize=15)\n",
    "# plt.xlabel(\"Epoch\", fontsize=13)\n",
    "# plt.ylabel(\"Loss\", fontsize=13)\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "# chart_path = f\"{SAVE_FOLDER}/Loss_E{epoch}_B{batch}.png\"\n",
    "# plt.savefig(chart_path, dpi=300)    \n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc8483d-fe95-4261-8786-2db8e90973aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"==================== TESTING ====================\")\n",
    "# test_loss, test_acc, test_f1, test_precision, test_recall, test_TNR, cumulative_testing_time = evaluate_model(model, test_loader, DEVICE, criterion, val_test=\"Test\", training_time=0, cumulative_testing_time=0)\n",
    "# print(\"\\n=======================================================\")\n",
    "# print(f\"✅ FINAL TEST PERFORMANCE (GAT Classifier):\")\n",
    "# print(f\"Accuracy: {test_acc:.4f} | F1-Score: {test_f1:.4f} | Loss: {test_loss:.4f} | Recall: {test_recall:.4f} | Precision: {test_precision:.4f} | TNR: {test_TNR:.4f}\")\n",
    "# print(\"=======================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c97117c-f333-454a-b87f-34e069af4ec8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (my_venv)",
   "language": "python",
   "name": "my_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
